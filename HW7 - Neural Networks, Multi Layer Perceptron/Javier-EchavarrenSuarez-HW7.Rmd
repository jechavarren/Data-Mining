---
title: "Homework 7"
output: 
  html_notebook:
  toc: yes
toc_float: yes
---

```{r} 
library(keras)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)

rm(list=ls())

# Set working directory as needed
setwd("C:/Users/Javier/Desktop/Data mining assignments/HW7")

df <- read.csv("wifi_localization.csv",header = TRUE, sep = "," )

# Seed the PRNG
set.seed(1122)
df <- df[sample(nrow(df)), ] # Shuffle, as all of the data in the .csv file
                             # is ordered by label!  

```
# --- Your code goes below ---
# (a)
# Part 2.1-a
2 Practicum problems
2.1 Feed Forward Neural Networks
Please use the template file (Problem-2-1-Template.Rmd) provided with the homework to bootstrap your code. The dataset available for this problem on Blackboard (wifi_localization.csv) is described in detail at https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization. It contains signal for 7 WiFi access points, which are used to predict a user’s location in one of four rooms. The response variable, therefore, is a room number ranging from 1-4. Using this dataset, you will train models to predict the user’s location. 80% of the data will be used for training and 20% for testing. Use the seed value of 1122 before you divide the data into a train and test set.


```{r}

#We divide the data into test and train
index <- sample(1:nrow(df), size= 0.8*nrow(df))
test.df<- df[-index,]
train.df<- df[index,]
```

(a) [1 point] Train a decision tree model on the training set, and fit the test set to the model. Print the confusion matrix, and summarize the confusion matrix in the format shown below:
Decision Tree Model
 Overall accuarcy: XX.XX
 Sensitivity Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 Specificity Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 PPV Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 Bal. Acc. Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 
```{r}
#We train the decision tree
tree <- rpart(room ~. , train.df, method = "class")
#We fit the test data to the model and print the confussion matrix
predictions1 <- predict(tree,test.df,type="class")
TestRoom <- as.factor(test.df$room)
CM <- confusionMatrix(predictions1,TestRoom)
print(CM$table)

#We print the summary as required
cat("Decision Tree Model
 Overall accuarcy:",gettextf("%0.2f",CM$overall[1]),"
 Sensitivity Class 1:",gettextf("%0.2f",CM$byClass[1,1]), "Class 2:",gettextf("%0.2f",CM$byClass[2,1]),"
             Class 3:",gettextf("%0.2f",CM$byClass[3,1]), "Class 4:", gettextf("%0.2f",CM$byClass[4,1]),"
 Specificity Class 1:",gettextf("%0.2f",CM$byClass[1,2]), "Class 2:",gettextf("%0.2f",CM$byClass[2,2]),"
             Class 3:",gettextf("%0.2f",CM$byClass[3,2]), "Class 4:", gettextf("%0.2f",CM$byClass[4,2]),"
 PPV         Class 1:",gettextf("%0.2f",CM$byClass[1,3]), "Class 2:",gettextf("%0.2f",CM$byClass[2,3]),"
             Class 3:",gettextf("%0.2f",CM$byClass[3,3]), "Class 4:", gettextf("%0.2f",CM$byClass[4,3]),"
 Bal. Acc.   Class 1:",gettextf("%0.2f",CM$byClass[1,11]), "Class 2:",gettextf("%0.2f",CM$byClass[2,11]),"
             Class 3:",gettextf("%0.2f",CM$byClass[3,11]), "Class 4:", gettextf("%0.2f",CM$byClass[4,11]))
```

You will now train a neural network to predict the user’s location in one of the four rooms. For the output layer, use the softmax activation function. Loss is measured in terms of accuracy, using ‘categorical_crossentropy’ on the ‘adam’ optimizer (see the compile() function). For the fit() method, set the batch_size to 32 and the validation_split to 0.20.
# (b)
# Note that in (b) either use a new variable to store the model, or null out
# the variable that stored the model in (a) if you want to reuse that variable.
# The reason is that if you don't null it out, the model in (b) will have
# residual information left over from (a) and your results will not be quite
# accurate.
(b) [2 points] In the first stage, use one hidden layer, and only one neuron in the hidden layer. Use the relu activation function for the neuron in the hidden layer. Train the network for 100 epochs. Fit the held out test dataset to the model and create (and print) the confusion matrix. Based on the training and the fitting of the model, answer the following questions:
```{r}
#We create the training matrix and label vector.
X_train <- select(train.df, -room)
y_train <- train.df$room-1
#we create the categorical label matrix
y_train.ohe <- to_categorical(y_train)

#We do the same for the test data
X_test <- select(test.df, -room)
y_test <- test.df$room-1
y_test.ohe <- to_categorical(y_test)

#We create the model
NN1 <- keras_model_sequential() %>%
  layer_dense(units = 1, activation="relu", input_shape=c(7)) %>%
  layer_dense(units = 4, activation="softmax")

NN1

#We compile the model
NN1 %>% 
  compile(loss = "categorical_crossentropy", 
          optimizer="adam", 
          metrics=c("accuracy"))

#We train the model
NN1 %>% fit(
  data.matrix(X_train), 
  y_train.ohe,
  epochs=100,
  batch_size=32,
  validation_split=0.20
)

#We see how accurate is the model
NN1.eval <- NN1 %>% evaluate(as.matrix(X_test), y_test.ohe)
```
# Part 2.1-b(i) 
Print out the loss and accuracy from fitting the test dataset. The output should be in the following form:
 For one neuron in hidden layer, loss: X.XX, Accuracy: X.XX

```{r}
#We print the results as required
cat(" For one neuron in hidden layer, loss: ",gettextf("%0.2f",NN1.eval[1]),", Accuracy:",gettextf("%0.2f",NN1.eval[2]))
```
# Part 2.1-b(ii)
Look at the plot for accuracy; why do you think the accuracy is low? (1-3 sentences.)
I think that the accuracy is low because the hidden layer with only one neuron acts as a bottleneck and can not distinguish well between different patterns, as it is only one neuron with a single function.
# Part 2.1-b(iii)
Examine the predicted labels, and print these out. What pattern do you see in the predicted labels?
```{r}
pred.prob <- predict(NN1, as.matrix(X_test))
pred.class <- apply(pred.prob, 1, function(x) which.max(x)-1)
print(pred.class)
```
-We see that the neural network always predicts the same value, 2, and that way it has very little predicting power, as it doesn't change with the input.

# Part 2.1-b(iii)
(iii) Is the bias of the model high or low or just about right? Why?
 -The bias is very high and the model's predictions are far from the target. It is so high because It always predicts the same class, and the real label is not always the same, resulting in a big difference.

# Part 2.1-b(iv)
(iv) Do you think we will get better results if we increase the training to 200 epochs? Why?
 -We will not get better results, as we can see from the plot that the model is not learning, accuracy stays the same as epochs pass because the model is in a local maximum.

Before starting the second stage below, either use a new variable to store the model, or null out the variable that stored the model in (a) if you want to reuse that variable. The reason is that if you don't null it out, the model in (b) will have residual information left over from (a) and your results will not be quite accurate.

# (c) 
(c) [2 points] In the second stage, improve your neural network such that it predicts with high accuracy. Start increasing the number of neurons in the hidden layer until the accuracy improves (should be in the high 0.90’s). Create the best model you can with one hidden layer by varying the number of neurons in the hidden layer. Fit the held out test dataset to the model. Based on the training and the fitting of the model, answer the following questions:

```{r}
#We create the model
NN2 <- keras_model_sequential() %>%
  layer_dense(units = 10, activation="relu", input_shape=c(7)) %>%
  layer_dense(units = 4, activation="softmax")

NN2

#We compile the model
NN2 %>% 
  compile(loss = "categorical_crossentropy", 
          optimizer="adam", 
          metrics=c("accuracy"))

#We train the model
NN2 %>% fit(
  data.matrix(X_train), 
  y_train.ohe,
  epochs=100,
  batch_size=32,
  validation_split=0.20
)
```
# Part 2.1-c(i)
(i) Print out the loss and accuracy from fitting the test dataset. The output should be in the following form:
 Best model has XX neurons in the hidden layer.
 In this model, loss: X.XX, Accuracy: X.XX
```{r}
#We see how accurate is the model
NN2.eval <- NN2 %>% evaluate(as.matrix(X_test), y_test.ohe)

#We print the results as required
cat(" Best model has 10 neurons in the hidden layer.
 In this model, loss:",gettextf("%0.2f",NN2.eval[1])," Accuracy:",gettextf("%0.2f",NN2.eval[2]))
```
# Part 2.1-c(ii)
(ii) Is the bias of the model high or low or just about right? Why?
-The bias of the model is low, as it predicts correctly 97% of the time, its prediction is near the real result. Its bias is low because each neuron in the hidden layer is able to measure a different feature, and the final neurons can make use of this different information to guess a good approximation of the real label.

# Part 2.1-c(iii)
(iii) Based on the plots of accuracy and validation, at what epoch do you think we should stop the training to minimize over-fitting?
-We should stop the training around epoch 30, as from that epoch the model doesn't learn too much (accuracy doesn't improve), and it starts overfitting the data.
# (d)
(d) [1 point] For the best model in (c), print the confusion matrix, and summarize the confusion matrix in the
format shown below:
Best Neural Network Model
 Overall accuarcy: XX.XX
 Sensitivity Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 Specificity Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 PPV Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX
 Bal. Acc. Class 1: XX.XX Class 2: XX.XX
 Class 3: XX.XX Class 4: XX.XX

```{r}
#We fit the test data to the model and print the confussion matrix
pred.prob3 <- predict(NN2, as.matrix(X_test))
pred.class3 <- apply(pred.prob3, 1, function(x) which.max(x))
TestRoom <- as.factor(test.df$room)
pred.class3 <- as.factor(pred.class3)
CM3 <- confusionMatrix(pred.class3,TestRoom)
print(CM3$table)

#We print the summary as required
cat("Best Neural Network Model
 Overall accuarcy:",gettextf("%0.2f",CM3$overall[1]),"
 Sensitivity Class 1:",gettextf("%0.2f",CM3$byClass[1,1]), "Class 2:",gettextf("%0.2f",CM3$byClass[2,1]),"
             Class 3:",gettextf("%0.2f",CM3$byClass[3,1]), "Class 4:", gettextf("%0.2f",CM3$byClass[4,1]),"
 Specificity Class 1:",gettextf("%0.2f",CM3$byClass[1,2]), "Class 2:",gettextf("%0.2f",CM3$byClass[2,2]),"
             Class 3:",gettextf("%0.2f",CM3$byClass[3,2]), "Class 4:", gettextf("%0.2f",CM3$byClass[4,2]),"
 PPV         Class 1:",gettextf("%0.2f",CM3$byClass[1,3]), "Class 2:",gettextf("%0.2f",CM3$byClass[2,3]),"
             Class 3:",gettextf("%0.2f",CM3$byClass[3,3]), "Class 4:", gettextf("%0.2f",CM3$byClass[4,3]),"
 Bal. Acc.   Class 1:",gettextf("%0.2f",CM3$byClass[1,11]), "Class 2:",gettextf("%0.2f",CM3$byClass[2,11]),"
             Class 3:",gettextf("%0.2f",CM3$byClass[3,11]), "Class 4:", gettextf("%0.2f",CM3$byClass[4,11]))
```

# Part 2.1-d(i)
(i) Compare the above output to similar output of a decision tree model in (a). Comment on what you observe.
 -The confusion matrices look very similar, and they both have similar accuracy, specificity ,PPV and Balanced Accuracy. The neural network does better predicting, but by a little bit only. they can be considered similar.
# Part 2.1-d(ii)
(ii) If you had to deploy one of these two models in production, which one would you choose and why?

-In this case, I would choose the decision tree, as both models have similar outputs but the decision tree is more quick to implement computationally and is explainable, so we can see if it has problems, and explain why we the model makes such predictions. 
